## 一、研究背景与意义
随着人工智能技术的迅猛发展，计算机视觉在人机交互、智能安防、心理健康评估等领域展现出巨大潜力。其中，**面部表情识别**（Facial Expression Recognition, FER）作为情感计算的核心任务之一，旨在通过分析人脸图像自动识别个体的情绪状态。人类的基本情绪通常可归纳为七类：愤怒、厌恶、恐惧、快乐、中性、悲伤和惊讶（Ekman & Friesen, 1971），这一分类体系已成为FER领域的标准。

传统表情识别方法依赖手工特征（如LBP、Gabor滤波器等），泛化能力有限。近年来，深度学习尤其是卷积神经网络（CNN）在图像识别任务中取得突破性进展。VGG16作为经典CNN架构，凭借其深层结构和良好的迁移学习能力，在FER任务中表现出优异性能。然而，仅依赖空间域特征可能忽略图像中的频域信息。**小波变换**作为一种多尺度分析工具，能够有效提取图像的纹理与边缘细节，尤其适用于低分辨率人脸图像（如FER常用数据集FER2013中48×48像素图像）。

因此，将VGG16的空间特征与小波变换的频域特征进行融合，有望提升模型对细微表情变化的感知能力，从而提高识别准确率。

---

## 二、研究内容
本课题围绕“基于VGG16与小波变换融合的表情识别系统”展开，主要研究内容包括：

### 2.1 模型架构设计
+ 采用**VGG16**作为主干网络，加载ImageNet预训练权重进行迁移学习；
+ 引入**Haar小波变换**对输入图像进行一级分解，提取低频近似系数作为频域特征；
+ 设计**特征融合模块**，将CNN高层特征图与小波特征通过双线性插值对齐后逐元素相加；
+ 替换原VGG16最后的分类层为7类全连接输出层，适配FER任务。

### 2.2 数据预处理与增强
+ 使用公开表情数据集（如FER2013或自建数据集），按7类组织；
+ 训练阶段采用随机裁剪、水平翻转等数据增强策略；
+ 验证/测试阶段采用中心裁剪，确保评估一致性；
+ 所有图像统一归一化至ImageNet均值与标准差。

### 2.3 系统功能实现
+ **训练模块**：支持模型训练、验证、最佳权重保存；
+ **评估模块**：计算准确率、精确率、召回率、F1分数，并生成混淆矩阵；
+ **Web服务模块**：基于Flask构建Web应用，支持图片上传、拖拽识别、结果可视化；
+ **可视化模块**：自动生成训练损失曲线、准确率曲线及混淆矩阵热力图。

### 2.4 技术创新点
+ **多模态特征融合**：首次将Haar小波变换与VGG16结合用于FER任务；
+ **端到端系统集成**：从模型训练到Web部署全流程打通，具备实际应用潜力。

---

## 三、实验过程
### 3.1 实验环境
+ **操作系统**：Windows 11  
+ **编程语言**：Python 3.11.4  
+ **深度学习框架**：PyTorch 1.8+  
+ **硬件平台**：NVIDIA RTX 3060 GPU（6GB显存），16GB RAM

### 3.2 数据集准备
+ 使用FER2013数据集，包含约35,000张48×48灰度人脸图像；
+ 按类别划分为7个子文件夹（angry, disgust, fear, happy, neutral, sad, surprise）；
+ 按8:2比例自动划分训练集与验证集。

### 3.3 模型训练流程
1. 加载VGG16预训练权重（`vgg16-pre.pth`）；
2. 冻结部分底层卷积层，仅微调高层及分类器；
3. 设置超参数：  
    - Epochs = 50  
    - Batch size = 16  
    - Learning rate = 0.0001  
    - Optimizer = Adam  
    - Loss function = CrossEntropyLoss
4. 每轮训练后在验证集上评估，保存验证准确率最高的模型（`vgg.pth`）；
5. 记录训练/验证损失与准确率，绘制曲线图。

### 3.4 特征融合实现
+ 对每张输入图像同步执行：
    - VGG16前向传播获取feature map；
    - Haar小波变换提取低频系数，经双线性插值缩放至与CNN特征图相同尺寸；
    - 两者相加后送入分类头。

### 3.5 Web系统开发
+ 使用Flask搭建后端API；
+ 前端页面（`up.html`）支持图片上传与拖拽；
+ 后端调用训练好的模型进行推理，返回表情类别及置信度；
+ 不同表情以预设颜色高亮显示（如快乐→橙色，悲伤→蓝色）。

---

### 
